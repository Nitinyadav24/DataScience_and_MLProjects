{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import datasets","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"i=datasets.load_iris()","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"i.feature_names","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['sepal length (cm)',\n 'sepal width (cm)',\n 'petal length (cm)',\n 'petal width (cm)']"},"metadata":{}}]},{"cell_type":"code","source":"df=pd.DataFrame(i.data, columns=i.feature_names)\ndf['Target']=i.target","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n\n   Target  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Target']=df['Target'].astype('category')","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df['Target'].value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"2    0.333333\n1    0.333333\n0    0.333333\nName: Target, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"pipeline that preprocesses the data, trains the model, and then evaluates it using cross-validation:","metadata":{}},{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Load digits dataset\ndigits = datasets.load_digits()\n\n# Create features matrix\nfeatures = digits.data\n\n# Create target vector\ntarget = digits.target","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create standardizer\nstandardizer = StandardScaler()\n\n# Create logistic regression object\nlogit = LogisticRegression()","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline that standardizes, then runs logistic regression\npipeline = make_pipeline(standardizer, logit)\n\n# Create k-Fold cross-validation\nkf = KFold(n_splits=10, shuffle=True, random_state=1)","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline that standardizes, then runs logistic regression\npipeline = make_pipeline(standardizer, logit)\n\n# Create k-Fold cross-validation\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Conduct k-fold cross-validation\ncv_results = cross_val_score(pipeline, # Pipeline\n                             features, # Feature matrix\n                             target, # Target vector\n                             cv=kf, # Performance metric\n                             scoring=\"accuracy\", # Loss function\n                             n_jobs=-1) # Use all CPU cores","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate mean\ncv_results.mean()","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0.9649101481756478"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"pd.Series(target).nunique()","metadata":{"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"# View score for all 10 folds\ncv_results","metadata":{"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"array([0.97297297, 0.96721311, 0.96685083, 0.96111111, 0.98324022,\n       0.94413408, 0.96648045, 0.9494382 , 0.97175141, 0.96590909])"},"metadata":{}}]},{"cell_type":"markdown","source":"preprocess data based on the training set and then apply those transformations to both the training and test set","metadata":{}},{"cell_type":"code","source":"# Import library\nfrom sklearn.model_selection import train_test_split\n\n# Create training and test sets\nfeatures_train, features_test, target_train, target_test = train_test_split(\n    features, target, test_size=0.1, random_state=1)\n\n# Fit standardizer to training set\nstandardizer.fit(features_train)\n\n# Apply to both training and test sets\nfeatures_train_std = standardizer.transform(features_train)\nfeatures_test_std = standardizer.transform(features_test)","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"scikit-learn’s pipeline package makes this easy to do while using cross-validation techniques. We first create a pipeline that preprocesses the data (e.g., standardizer) and then trains a model (logistic regression, logit):","metadata":{}},{"cell_type":"code","source":"# Create a pipeline\npipeline = make_pipeline(standardizer, logit)","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"features_test.shape","metadata":{"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(180, 64)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Lets use ensemble on the Digits data ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nlog_clf = LogisticRegression()\nrnd_clf = RandomForestClassifier()\nsvm_clf = SVC()\n\nvoting_clf = VotingClassifier(\n    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n    voting='hard')\nvoting_clf.fit(features_train, target_train)","metadata":{"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('lr',\n                              LogisticRegression(C=1.0, class_weight=None,\n                                                 dual=False, fit_intercept=True,\n                                                 intercept_scaling=1,\n                                                 l1_ratio=None, max_iter=100,\n                                                 multi_class='warn',\n                                                 n_jobs=None, penalty='l2',\n                                                 random_state=None,\n                                                 solver='warn', tol=0.0001,\n                                                 verbose=0, warm_start=False)),\n                             ('rf',\n                              RandomForestClassifier(bootstrap=True,\n                                                     class_weight=None,\n                                                     criterion='gini',...\n                                                     oob_score=False,\n                                                     random_state=None,\n                                                     verbose=0,\n                                                     warm_start=False)),\n                             ('svc',\n                              SVC(C=1.0, cache_size=200, class_weight=None,\n                                  coef0=0.0, decision_function_shape='ovr',\n                                  degree=3, gamma='auto_deprecated',\n                                  kernel='rbf', max_iter=-1, probability=False,\n                                  random_state=None, shrinking=True, tol=0.001,\n                                  verbose=False))],\n                 flatten_transform=True, n_jobs=None, voting='hard',\n                 weights=None)"},"metadata":{}}]},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.ensemble import VotingClassifier\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.svm import SVC\n\n# log_clf = LogisticRegression()\n# rnd_clf = RandomForestClassifier()\n# svm_clf = SVC()\n\n# voting_clf = VotingClassifier(\n#     estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n#     voting='soft') # Soft voting will use Class_proba () method to take class with highest probabilities \n# voting_clf.fit(features_train, target_train)","metadata":{"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('lr',\n                              LogisticRegression(C=1.0, class_weight=None,\n                                                 dual=False, fit_intercept=True,\n                                                 intercept_scaling=1,\n                                                 l1_ratio=None, max_iter=100,\n                                                 multi_class='warn',\n                                                 n_jobs=None, penalty='l2',\n                                                 random_state=None,\n                                                 solver='warn', tol=0.0001,\n                                                 verbose=0, warm_start=False)),\n                             ('rf',\n                              RandomForestClassifier(bootstrap=True,\n                                                     class_weight=None,\n                                                     criterion='gini',...\n                                                     oob_score=False,\n                                                     random_state=None,\n                                                     verbose=0,\n                                                     warm_start=False)),\n                             ('svc',\n                              SVC(C=1.0, cache_size=200, class_weight=None,\n                                  coef0=0.0, decision_function_shape='ovr',\n                                  degree=3, gamma='auto_deprecated',\n                                  kernel='rbf', max_iter=-1, probability=False,\n                                  random_state=None, shrinking=True, tol=0.001,\n                                  verbose=False))],\n                 flatten_transform=True, n_jobs=None, voting='soft',\n                 weights=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Lets look at the accuracy ","metadata":{}},{"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')","metadata":{"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfor clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n    clf.fit(features_train, target_train)\n    y_pred = clf.predict(features_test)\n    print(clf.__class__.__name__, accuracy_score(target_test, y_pred))\n","metadata":{"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"LogisticRegression 0.9777777777777777\nRandomForestClassifier 0.9555555555555556\nSVC 0.5\nVotingClassifier 0.9666666666666667\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using Bagging Classifier ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nbag_clf = BaggingClassifier(\n    DecisionTreeClassifier(), n_estimators=500,\n    max_samples=100, bootstrap=True, n_jobs=-1)\nbag_clf.fit(features_train, target_train)\ny_pred = bag_clf.predict(features_test)","metadata":{"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}